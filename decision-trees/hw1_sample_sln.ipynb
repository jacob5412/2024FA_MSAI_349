{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8e81c1-6084-49fe-9908-aacdb2332b52",
   "metadata": {},
   "source": [
    "# Homework - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab9191-13bc-41d2-8b08-81256ee58cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import ID3\n",
    "import matplotlib.pyplot as plt\n",
    "import parse\n",
    "\n",
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940417b4-0903-4df2-990b-28e10c64a81b",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cb398-9b43-4a0b-8981-168a38482dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mini_auto_grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2957ee6-e7ac-4b78-89ad-99ff3eecac78",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366fe1f-eb01-486a-96d2-da1ef1a5b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    training_sizes,\n",
    "    avg_accuracies_with_pruning,\n",
    "    avg_accuracies_without_pruning,\n",
    "    dataset_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves.\n",
    "\n",
    "    Args:\n",
    "        training_sizes: List of training set sizes\n",
    "        avg_accuracies_with_pruning: List of average accuracies with pruning\n",
    "        avg_accuracies_without_pruning: List of average accuracies\n",
    "                                        without pruning\n",
    "        dataset_name: name of the dataset of plot title and image filename.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_accuracies_with_pruning,\n",
    "        label=\"With Pruning\",\n",
    "        color=\"orange\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_accuracies_without_pruning,\n",
    "        label=\"Without Pruning\",\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Training Examples\")\n",
    "    plt.ylabel(\"Average Accuracy on Test Data\")\n",
    "    plt.title(f\"Learning Curves for {dataset_name} Data With and Without Pruning\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"images/learning_curve_{dataset_name}.png\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved image as images/learning_curve_{dataset_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2ff20-8faf-4a0f-a421-0b8d276c0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = range(10, 305, 5)\n",
    "loop_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c79da-9515-482b-b5bd-9049ac434807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse.parse(\"house_votes_84.data\")\n",
    "avg_test_accuracy_with_pruning = []\n",
    "avg_test_accuracy_without_pruning = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a42da-79ca-4892-afdb-26429c3f3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_size in training_sizes:\n",
    "    with_pruning = []\n",
    "    without_pruning = []\n",
    "\n",
    "    for _ in range(loop_size):\n",
    "        random.shuffle(data)\n",
    "        validation_size = max(1, math.ceil((int(train_size / 0.8) - train_size) // 2))\n",
    "        test_size = validation_size\n",
    "        train = data[:train_size]\n",
    "        valid = data[train_size : train_size + validation_size]\n",
    "        test = data[\n",
    "            train_size + validation_size : train_size + validation_size + test_size\n",
    "        ]\n",
    "\n",
    "        # pruned tree\n",
    "        tree = ID3.ID3(train, 0)\n",
    "        ID3.prune(tree, valid)\n",
    "        acc = ID3.test(tree, test)\n",
    "        with_pruning.append(acc)\n",
    "\n",
    "        # non-pruned tree\n",
    "        tree = ID3.ID3(train + valid, 0)\n",
    "        acc = ID3.test(tree, test)\n",
    "        without_pruning.append(acc)\n",
    "\n",
    "    avg_accuracy_with_pruning = sum(with_pruning) / len(with_pruning)\n",
    "    avg_accuracy_without_pruning = sum(without_pruning) / len(without_pruning)\n",
    "    avg_test_accuracy_with_pruning.append(avg_accuracy_with_pruning)\n",
    "    avg_test_accuracy_without_pruning.append(avg_accuracy_without_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b41529-23e3-428b-9d90-c52d0b8d4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_with_pruning,\n",
    "    avg_test_accuracy_without_pruning,\n",
    "    dataset_name=\"House Data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494f859-5ca0-4827-b41e-84d701e142ee",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c60c22-33c2-44cf-90c6-ec7e5c0f7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    Random Forest - an ensemble learning technique that builds multiple trees.\n",
    "    Here, we're building trees using bootstrapping (sampling with replacement)\n",
    "\n",
    "    Attributes:\n",
    "        random_forest_nodes (list): A list to store the decision tree nodes\n",
    "                                     in the random forest.\n",
    "        num_trees (int): The number of decision trees in the random forest.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        self.random_forest_nodes = []\n",
    "        self.num_trees = num_trees\n",
    "\n",
    "    def fit(self, examples):\n",
    "        \"\"\"\n",
    "        Fits the random forest to a dataset using bootstrapped samples and\n",
    "        creates decision trees.\n",
    "        \"\"\"\n",
    "        for _ in range(self.num_trees):\n",
    "            # create a bootstrapped sample by randomly selecting an example n\n",
    "            # times; with replacement, i.e., can select one example more than\n",
    "            # once; n = len(examples)\n",
    "            bootstrap_sample = [random.choice(examples) for _ in range(len(examples) + 1)]\n",
    "            available_attributes = [\n",
    "                attribute for attribute in examples[0].keys() if attribute != \"Class\"\n",
    "            ]\n",
    "            subset_attributes = set(\n",
    "                random.sample(\n",
    "                    available_attributes,\n",
    "                    random.randint(2, len(available_attributes)),\n",
    "                )\n",
    "            )\n",
    "            random_forest_node = ID3.ID3_helper(bootstrap_sample, subset_attributes)\n",
    "            self.random_forest_nodes.append(random_forest_node)\n",
    "\n",
    "    def test(self, examples):\n",
    "        \"\"\"\n",
    "        Tests the accuracy of the random forest on a dataset.\n",
    "        \"\"\"\n",
    "        num_correct_predictions = sum(\n",
    "            [self.evaluate(example) == example[\"Class\"] for example in examples]\n",
    "        )\n",
    "        return num_correct_predictions / len(examples)\n",
    "\n",
    "    def evaluate(self, example):\n",
    "        \"\"\"\n",
    "        Evaluates a single example using the random forest's ensemble of\n",
    "        decision trees. Use majority voting to predict the class.\n",
    "        \"\"\"\n",
    "        predictions = [\n",
    "            ID3.evaluate(random_forest_node, example)\n",
    "            for random_forest_node in self.random_forest_nodes\n",
    "        ]\n",
    "        return ID3.get_most_common_class(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5458-350d-4fe5-b712-979bf13396a5",
   "metadata": {},
   "source": [
    "### Best Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe0313-b515-4ed7-a957-8b7891651d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse.parse(\"candy.data\")\n",
    "num_trees_accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118984e-0b97-4910-a926-946a665441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_trees in range(2, 15):\n",
    "    accuracies = []\n",
    "    for _ in range(25):\n",
    "        random.shuffle(data)\n",
    "        split_index = int(0.8 * len(data))\n",
    "        train = data[:split_index]\n",
    "        test = data[split_index:]\n",
    "\n",
    "        random_forest = RandomForest(num_trees)\n",
    "        random_forest.fit(train)\n",
    "        acc = random_forest.test(test)\n",
    "        accuracies.append(acc)\n",
    "    num_trees_accuracies[num_trees] = sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6646bf-6eaa-4f56-9815-b82a5c01330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = list(num_trees_accuracies.keys())\n",
    "accuracy = list(num_trees_accuracies.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trees, accuracy, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Random Forest Accuracy vs. Number of Trees\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Average Accuracy on Test Data\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"images/rf_num_trees_accuracies.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc5f9e-95c9-4668-bf66-2a2bfb1f0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_trees = max(num_trees_accuracies, key=lambda key: num_trees_accuracies[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ae8d-2fad-4253-8808-2378e077d3e3",
   "metadata": {},
   "source": [
    "### Comparison with ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280b73b-5545-4430-a6cc-e03b2082ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_accuracy_id3_pruning = []\n",
    "avg_test_accuracy_id3_not_pruning = []\n",
    "avg_test_accuracy_rf = []\n",
    "avg_train_accuracy_id3_pruning = []\n",
    "avg_train_accuracy_id3_not_pruning = []\n",
    "avg_train_accuracy_rf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a48da6-e487-4125-a909-b00b1e7518c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = range(5, 68, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85357425-ef6e-4f42-9a6e-7506b9055cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_size in training_sizes:\n",
    "    with_pruning_acc_test = []\n",
    "    without_pruning_acc_test = []\n",
    "    rf_acc_test = []\n",
    "    with_pruning_acc_train = []\n",
    "    without_pruning_acc_train = []\n",
    "    rf_acc_train = []\n",
    "\n",
    "    for _ in range(25):\n",
    "        random.shuffle(data)\n",
    "        validation_size = max(1, math.ceil((int(train_size / 0.8) - train_size) // 2))\n",
    "        test_size = validation_size\n",
    "        train = data[:train_size]\n",
    "        valid = data[train_size : train_size + validation_size]\n",
    "        test = data[\n",
    "            train_size + validation_size : train_size + validation_size + test_size\n",
    "        ]\n",
    "\n",
    "        tree = ID3.ID3(train, 0)\n",
    "        acc = ID3.test(tree, train)\n",
    "        with_pruning_acc_train.append(acc)\n",
    "        ID3.prune(tree, valid)\n",
    "        acc = ID3.test(tree, test)\n",
    "        with_pruning_acc_test.append(acc)\n",
    "\n",
    "        tree = ID3.ID3(train + valid, 0)\n",
    "        acc = ID3.test(tree, train + valid)\n",
    "        without_pruning_acc_train.append(acc)\n",
    "        acc = ID3.test(tree, test)\n",
    "        without_pruning_acc_test.append(acc)\n",
    "\n",
    "        random_forest = RandomForest(num_trees)\n",
    "        random_forest.fit(train + valid)\n",
    "        acc = random_forest.test(train + valid)\n",
    "        rf_acc_train.append(acc)\n",
    "        acc = random_forest.test(test)\n",
    "        rf_acc_test.append(acc)\n",
    "\n",
    "    avg_test_accuracy_id3_pruning.append(\n",
    "        sum(with_pruning_acc_test) / len(with_pruning_acc_test)\n",
    "    )\n",
    "    avg_test_accuracy_id3_not_pruning.append(\n",
    "        sum(without_pruning_acc_test) / len(without_pruning_acc_test)\n",
    "    )\n",
    "    avg_test_accuracy_rf.append(sum(rf_acc_test) / len(rf_acc_test))\n",
    "    avg_train_accuracy_id3_pruning.append(\n",
    "        sum(with_pruning_acc_train) / len(with_pruning_acc_train)\n",
    "    )\n",
    "    avg_train_accuracy_id3_not_pruning.append(\n",
    "        sum(without_pruning_acc_train) / len(without_pruning_acc_train)\n",
    "    )\n",
    "    avg_train_accuracy_rf.append(sum(rf_acc_train) / len(rf_acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae732d-e2b1-4c4c-8f31-2270832d0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_forest_id3_accuracies(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_id3_pruning,\n",
    "    avg_test_accuracy_id3_not_pruning,\n",
    "    avg_test_accuracy_rf,\n",
    "    avg_train_accuracy_id3_pruning,\n",
    "    avg_train_accuracy_id3_not_pruning,\n",
    "    avg_train_accuracy_rf,\n",
    "    dataset_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_id3_pruning,\n",
    "        label=\"[Test] ID3 (With Pruning)\",\n",
    "        color=\"orange\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_id3_not_pruning,\n",
    "        label=\"[Test] ID3 (Without Pruning)\",\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_rf,\n",
    "        label=\"[Test] Random Forest\",\n",
    "        color=\"green\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_id3_pruning,\n",
    "        label=\"[Train] ID3 (With Pruning)\",\n",
    "        color=\"orange\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_id3_not_pruning,\n",
    "        label=\"[Train] ID3 (Without Pruning)\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_rf,\n",
    "        label=\"[Train] Random Forest\",\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Training Examples\")\n",
    "    plt.ylabel(\"Average Accuracy\")\n",
    "    plt.title(\n",
    "        f\"Learning Curves for {dataset_name} Data - ID3 (With and Without Pruning) vs Random Forest\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"images/id3_vs_rf_{dataset_name}.png\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved image as images/id3_vs_rf_{dataset_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b4b97-9810-44ab-bff7-3fa6a9c39bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_forest_id3_accuracies(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_id3_pruning,\n",
    "    avg_test_accuracy_id3_not_pruning,\n",
    "    avg_test_accuracy_rf,\n",
    "    avg_train_accuracy_id3_pruning,\n",
    "    avg_train_accuracy_id3_not_pruning,\n",
    "    avg_train_accuracy_rf,\n",
    "    \"Candy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11944651-c607-41cd-b7c3-7a32060c1cf9",
   "metadata": {},
   "source": [
    "### Comparing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102f834-8de1-4413-9b55-cd98840128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_pruning_acc = []\n",
    "without_pruning = []\n",
    "rf_acc = []\n",
    "\n",
    "for _ in range(25):\n",
    "    random.shuffle(data)\n",
    "    train = data[: len(data) // 2]\n",
    "    valid = data[len(data) // 2 : 3 * len(data) // 4]\n",
    "    test = data[3 * len(data) // 4 :]\n",
    "\n",
    "    tree = ID3.ID3(train, 0)\n",
    "    ID3.prune(tree, valid)\n",
    "    acc = ID3.test(tree, test)\n",
    "    with_pruning_acc.append(acc)\n",
    "\n",
    "    tree = ID3.ID3(train + valid, 0)\n",
    "    acc = ID3.test(tree, test)\n",
    "    without_pruning.append(acc)\n",
    "\n",
    "    random_forest = RandomForest(num_trees)\n",
    "    random_forest.fit(train + valid)\n",
    "    acc = random_forest.test(test)\n",
    "    rf_acc.append(acc)\n",
    "print(\n",
    "    \"Avg accuracy of ID3 with pruning: \",\n",
    "    sum(with_pruning_acc) / len(with_pruning_acc),\n",
    ")\n",
    "print(\n",
    "    \"Avg accuracy of ID3 without pruning: \",\n",
    "    sum(without_pruning) / len(without_pruning),\n",
    ")\n",
    "print(\n",
    "    \"Avg accuracy of RF: \",\n",
    "    sum(rf_acc) / len(rf_acc),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9badb5-b8ee-4371-8da7-fed86a5c2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

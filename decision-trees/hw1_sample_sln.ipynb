{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8e81c1-6084-49fe-9908-aacdb2332b52",
   "metadata": {},
   "source": [
    "# Homework #1: Decision Trees using ID3\n",
    "\n",
    "* This notebook should help guide you in writing code for your homework.\n",
    "* Please submit this notebook along with your writeup.\n",
    "* In this assignment, you will implement the ID3 algorithm to build a decision tree.\n",
    "* Follow the steps below to complete your implementation. Remember to test your code thoroughly using the provided datasets and unit tests.\n",
    "* Using any assistive tools to generate your code or write up is strictly prohibited per the course guidelines.\n",
    "\n",
    "Good luck and have fun! <(^_^)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab9191-13bc-41d2-8b08-81256ee58cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940417b4-0903-4df2-990b-28e10c64a81b",
   "metadata": {},
   "source": [
    "* The above imports should have you covered.\n",
    "* You may **not** use an additional external packages to complete this assignment. These include, but are not limited to-`numpy` or `pandas`.\n",
    "* You may use `sklearn` for your confusion matrix.\n",
    "* You may use built-in libraries like `collections`, `os`, `sys`, and so forth to read in files and handle your data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cb398-9b43-4a0b-8981-168a38482dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filename):\n",
    "    \"\"\"\n",
    "    Takes a filename and returns attribute information and all the data in array of dictionaries\n",
    "\n",
    "    ------ Do not modify this function --------\n",
    "    \"\"\"\n",
    "    # initialize variables\n",
    "\n",
    "    out = []\n",
    "    # note: you may need to add encoding=\"utf-8\" as a parameter\n",
    "    csvfile = open(filename, \"r\")\n",
    "    fileToRead = csv.reader(csvfile)\n",
    "\n",
    "    headers = next(fileToRead)\n",
    "\n",
    "    # iterate through rows of actual data\n",
    "    for row in fileToRead:\n",
    "        out.append(dict(zip(headers, row)))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1134b-79c7-40b6-8557-c6502e483e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "house_votes_data = parse(\"house_votes_84.data\")\n",
    "house_votes_data[0]  # list of dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d87aee-4129-4f53-8d4d-2a5edf806c08",
   "metadata": {},
   "source": [
    "## Implementing Data Structures\n",
    "\n",
    "Start by writing up your node class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52518d-8311-487f-9039-ecb359d43c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Represents a node in a ID3 decision tree.\n",
    "\n",
    "    Attributes:\n",
    "        attribute (str): The attribute on which the data is split.\n",
    "        attribute_value (str): The value of the attribute for this node.\n",
    "        class_label (str): The class label if it's leaf node, otherwise\n",
    "                           the majority class if it's a non-leaf node.\n",
    "        children (dict of Node): Dictionary of child nodes of the\n",
    "                                 form {attribute_value:child_node}.\n",
    "        is_leaf (bool): True if it's a leaf node, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        attribute=None,\n",
    "        attribute_value=None,\n",
    "        class_label=None,\n",
    "        is_leaf=False,\n",
    "    ):\n",
    "        self.attribute = attribute\n",
    "        self.attribute_value = attribute_value\n",
    "        self.class_label = class_label\n",
    "        self.children = {}\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "    def has_children(self):\n",
    "        \"\"\"\n",
    "        Returns True if current node has children, False otherwise.\n",
    "        \"\"\"\n",
    "        return bool(self.children)\n",
    "\n",
    "    def get_children(self):\n",
    "        \"\"\"\n",
    "        Returns children of current node.\n",
    "        \"\"\"\n",
    "        return self.children.items()\n",
    "\n",
    "    def add_child(self, attribute_value, child_node):\n",
    "        \"\"\"\n",
    "        Add a child node to the current node with a given attribute value.\n",
    "        \"\"\"\n",
    "        self.children[attribute_value] = child_node\n",
    "\n",
    "    def get_attribute(self):\n",
    "        \"\"\"\n",
    "        Returns attribute of current node.\n",
    "        \"\"\"\n",
    "        return self.attribute\n",
    "\n",
    "    def update_attribute(self, attribute):\n",
    "        \"\"\"\n",
    "        Updates attribute of current node.\n",
    "        \"\"\"\n",
    "        self.attribute = attribute\n",
    "\n",
    "    def update_as_leaf(self, is_leaf=True):\n",
    "        \"\"\"\n",
    "        Update current node to a leaf node.\n",
    "        \"\"\"\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "    def update_class_label(self, class_label):\n",
    "        \"\"\"\n",
    "        Update class label of current node.\n",
    "        \"\"\"\n",
    "        self.class_label = class_label\n",
    "\n",
    "    def display(self, indent=0):\n",
    "        \"\"\"\n",
    "        (Debugging) Displays a node and its children.\n",
    "        \"\"\"\n",
    "        prefix = \"  \" * indent\n",
    "        if self.is_leaf:\n",
    "            print(f\"| {prefix}└─Class: {self.class_label}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{'|' if indent != 0 else ''}{prefix}\"\n",
    "                + f\"{'└─' if indent != 0 else ''}\"\n",
    "                + f\"Attribute: {self.get_attribute()}\"\n",
    "            )\n",
    "            for value, child_node in self.get_children():\n",
    "                print(f\"|{prefix} └─Value {value}:\")\n",
    "                child_node.display(indent + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b4faa-bd3d-4401-8f83-7b1d33598611",
   "metadata": {},
   "source": [
    "* Now implement the ID3 algorithm using the node data structure you created.\n",
    "* You may overload the following functions and create more as you please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efd143-fe78-4dd5-98e8-cf3414e78902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(examples, default):\n",
    "    \"\"\"\n",
    "    Takes in an array of examples, and returns a tree (an instance of Node)\n",
    "    trained on the examples.  Each example is a dictionary of attribute:value\n",
    "    pairs, and the target class variable is a special attribute with the name\n",
    "    \"Class\". Any missing attributes are denoted with a value of \"?\".\n",
    "    \"\"\"\n",
    "    # if there are no examples, return the default value\n",
    "    if len(examples) == 0:\n",
    "        node = Node(default)\n",
    "        return node\n",
    "    attributes = set(\n",
    "        attribute for attribute in examples[0].keys() if attribute != \"Class\"\n",
    "    )\n",
    "    node = ID3_helper(examples, attributes)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fbe72-d81b-4da9-aeb3-1badd57a18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_class(class_labels):\n",
    "    \"\"\"\n",
    "    Return the class with the most number of examples.\n",
    "    \"\"\"\n",
    "    return Counter(class_labels).most_common()[0][0]\n",
    "\n",
    "\n",
    "def get_entropy(examples):\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a set of examples.\n",
    "    \"\"\"\n",
    "    class_labels_count = Counter([example[\"Class\"] for example in examples])\n",
    "    entropy = 0\n",
    "    for class_label_count in class_labels_count.items():\n",
    "        proportion = class_label_count[1] / len(examples)\n",
    "        entropy += -proportion * math.log2(proportion)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def get_info_gain(examples, attribute):\n",
    "    \"\"\"\n",
    "    Return the information gain for a set of examples and attributes.\n",
    "    \"\"\"\n",
    "    parent_entropy = get_entropy(examples)\n",
    "    attribute_values = set(example[attribute] for example in examples)\n",
    "    weighted_entropy = 0\n",
    "    for attribute_value in attribute_values:\n",
    "        child_examples = [\n",
    "            example for example in examples if example[attribute] == attribute_value\n",
    "        ]\n",
    "        child_entropy = get_entropy(child_examples)\n",
    "        weighted_entropy += (len(child_examples) / len(examples)) * child_entropy\n",
    "    info_gain = parent_entropy - weighted_entropy\n",
    "    return info_gain\n",
    "\n",
    "\n",
    "def prune(node, examples):\n",
    "    \"\"\"\n",
    "    Takes in a trained tree and a validation set of examples. Prunes nodes in\n",
    "    order to improve accuracy on the validation data; the precise pruning\n",
    "    strategy is up to you.\n",
    "    \"\"\"\n",
    "    accuracy_based_pruning(node, examples)\n",
    "\n",
    "\n",
    "def accuracy_based_pruning(node, examples):\n",
    "    \"\"\"\n",
    "    Recursively prune a tree by cutting off children until accuracy on the\n",
    "    validation set stops improving.\n",
    "    \"\"\"\n",
    "    # stop once you reach the leaf, since you can't prune further\n",
    "    if node.is_leaf:\n",
    "        return\n",
    "\n",
    "    # get to the max depth recursively\n",
    "    for _, child_node in node.get_children():\n",
    "        accuracy_based_pruning(child_node, examples)\n",
    "\n",
    "    # Pruning starts once we reach the max depth\n",
    "    pre_pruning_accuracy = test_tree(node, examples)\n",
    "    node.is_leaf = True\n",
    "    post_pruning_accuracy = test_tree(node, examples)\n",
    "\n",
    "    # only prune the tree if the accuracy is better\n",
    "    if post_pruning_accuracy <= pre_pruning_accuracy:\n",
    "        node.is_leaf = False\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ebb8a-8a1a-4a45-8b21-7b392e31341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree(node, examples, return_predictions=False):\n",
    "    \"\"\"\n",
    "    Takes in a trained tree and a test set of examples.\n",
    "    If return_predictions is True, returns the predicted classes for all examples.\n",
    "    Otherwise, returns the accuracy (fraction of examples the tree classifies correctly).\n",
    "    \"\"\"\n",
    "    predictions = [evaluate(node, example) for example in examples]\n",
    "\n",
    "    if return_predictions:\n",
    "        # Return the list of predictions for confusion matrix\n",
    "        return predictions\n",
    "\n",
    "    # Calculate accuracy if return_predictions is False\n",
    "    num_correct_predictions = sum(\n",
    "        [pred == example[\"Class\"] for pred, example in zip(predictions, examples)]\n",
    "    )\n",
    "    return num_correct_predictions / len(examples)  # accuracy\n",
    "\n",
    "\n",
    "def evaluate(node, example):\n",
    "    \"\"\"\n",
    "    Takes in a tree and one example. Returns the Class value that the tree\n",
    "    assigns to the example.\n",
    "    \"\"\"\n",
    "    # recursively traverse the tree, until you reach a leaf node\n",
    "    if node.is_leaf:\n",
    "        return node.class_label\n",
    "\n",
    "    node_attribute = node.get_attribute()\n",
    "    example_attribute_value = example.get(node_attribute)\n",
    "    child_node = node.children.get(example_attribute_value)\n",
    "\n",
    "    # if attribute value is missing or if tree is pruned,\n",
    "    # we won't have children for certain attribute values,\n",
    "    # class_label here is the majority class\n",
    "    if not child_node:\n",
    "        return node.class_label\n",
    "    return evaluate(child_node, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538afde-cbe7-42f8-85f9-2ecda300efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3_helper(examples, attributes, missing_values=\"keep\"):\n",
    "    \"\"\"\n",
    "    Recursively creates a decision tree.\n",
    "    \"\"\"\n",
    "    node = Node()\n",
    "    class_labels = [example[\"Class\"] for example in examples]\n",
    "\n",
    "    # this class label would be useful during pruning\n",
    "    node.update_class_label(get_most_common_class(class_labels))\n",
    "\n",
    "    # if all examples belong to the same class, update as leaf and return\n",
    "    if len(set(class_labels)) == 1:\n",
    "        node.update_as_leaf()\n",
    "        return node\n",
    "\n",
    "    # if no attributes remaining or if no examples remaining, update as leaf\n",
    "    # and use most common class\n",
    "    if not attributes or len(examples) == 0:\n",
    "        node.update_as_leaf()\n",
    "        return node\n",
    "\n",
    "    # get best_attribute based on information gain (info_gain)\n",
    "    attribute_info_gain = {}\n",
    "    for attribute in attributes:\n",
    "        attribute_info_gain[attribute] = get_info_gain(examples, attribute)\n",
    "    best_attribute = max(\n",
    "        attribute_info_gain,\n",
    "        key=lambda key: attribute_info_gain[key],\n",
    "    )\n",
    "    node.update_attribute(best_attribute)\n",
    "\n",
    "    # recursively create child nodes based on the best attribute values\n",
    "    if missing_values == \"ignore\":\n",
    "        best_attribute_values = set(\n",
    "            example[best_attribute]\n",
    "            for example in examples\n",
    "            if example[best_attribute] != \"?\"\n",
    "        )\n",
    "    elif missing_values == \"keep\":\n",
    "        best_attribute_values = set(example[best_attribute] for example in examples)\n",
    "    for best_attribute_value in best_attribute_values:\n",
    "        child_examples = [\n",
    "            example\n",
    "            for example in examples\n",
    "            if example[best_attribute] == best_attribute_value\n",
    "        ]\n",
    "        child_attributes = set(\n",
    "            attribute for attribute in attributes if attribute != best_attribute\n",
    "        )\n",
    "        child_node = ID3_helper(child_examples, child_attributes)\n",
    "        node.add_child(best_attribute_value, child_node)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b51ce9-122f-4b1d-8467-6ad2a837c92e",
   "metadata": {},
   "source": [
    "## Testing Basic Implementation\n",
    "\n",
    "* You can test your implementation of ID3 using the function below.\n",
    "* If your code works as directed, all the test cases would pass.\n",
    "* They test the following:\n",
    "    * Case 1: A simple test with two examples that belong to the same class. The decision tree should correctly classify both examples.\n",
    "    * Case 2: two different class labels.\n",
    "    * Case 3: Involves different classes and multiple attribute values. The tree should be able to distinguish between different classes.\n",
    "    * Case 4: Checks whether the implementation can handle missing attributes, denoted by \"?\". The tree should still classify the examples correctly even when some attributes are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f855e5-b10d-427b-a0f7-93d914d5adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_grader():\n",
    "    data = [dict(a=1, b=0, Class=1), dict(a=1, b=1, Class=1)]\n",
    "\n",
    "    try:\n",
    "        tree = ID3(data, 0)\n",
    "        if tree != None:\n",
    "            ans = evaluate(tree, dict(a=1, b=0))\n",
    "            if ans != 1:\n",
    "                print(\"ID3 test 1 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 1 succeeded.\")\n",
    "        else:\n",
    "            print(\"ID3 test 1 failed -- no tree returned\")\n",
    "    except Exception as e:\n",
    "        print(f\"ID3 test 1 failed runtime error: {e}\")\n",
    "\n",
    "    data = [dict(a=1, b=0, Class=0), dict(a=1, b=1, Class=1)]\n",
    "\n",
    "    try:\n",
    "        tree = ID3(data, 0)\n",
    "        if tree != None:\n",
    "            ans = evaluate(tree, dict(a=1, b=0))\n",
    "            if ans != 0:\n",
    "                print(\"ID3 test 2 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 2 succeeded.\")\n",
    "        else:\n",
    "            print(\"ID3 test 2 failed -- no tree returned\")\n",
    "    except Exception as e:\n",
    "        print(f\"ID3 test 2 failed runtime error: {e}\")\n",
    "\n",
    "    data = [\n",
    "        dict(a=1, b=0, Class=2),\n",
    "        dict(a=1, b=1, Class=1),\n",
    "        dict(a=2, b=0, Class=2),\n",
    "        dict(a=2, b=1, Class=3),\n",
    "        dict(a=3, b=0, Class=1),\n",
    "        dict(a=3, b=1, Class=3),\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        tree = ID3(data, 0)\n",
    "        if tree != None:\n",
    "            ans = evaluate(tree, dict(a=1, b=0))\n",
    "            if ans != 2:\n",
    "                print(\"ID3 test 3-1 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 3-1 succeeded.\")\n",
    "            ans = evaluate(tree, dict(a=1, b=1))\n",
    "            if ans != 1:\n",
    "                print(\"ID3 test 3-2 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 3-2 succeeded.\")\n",
    "        else:\n",
    "            print(\"ID3 test 3 failed -- no tree returned\")\n",
    "    except Exception as e:\n",
    "        print(f\"ID3 test 3 failed runtime error: {e}\")\n",
    "\n",
    "    data = [\n",
    "        dict(a=1, b=0, c=\"?\", Class=1),\n",
    "        dict(a=1, b=3, c=2, Class=1),\n",
    "        dict(a=2, b=\"?\", c=1, Class=2),\n",
    "        dict(a=2, b=1, c=3, Class=2),\n",
    "        dict(a=3, b=0, c=1, Class=3),\n",
    "        dict(a=3, b=2, c=\"?\", Class=3),\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        tree = ID3(data, 0)\n",
    "        if tree != None:\n",
    "            ans = evaluate(tree, dict(a=1, b=1, c=1))\n",
    "            if ans != 1:\n",
    "                print(\"ID3 test 4-1 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 4-1 succeeded.\")\n",
    "            ans = evaluate(tree, dict(a=2, b=0, c=0))\n",
    "            if ans != 2:\n",
    "                print(\"ID3 test 4-2 failed.\")\n",
    "            else:\n",
    "                print(\"ID3 test 4-2 succeeded.\")\n",
    "        else:\n",
    "            print(\"ID3 test 4 failed -- no tree returned\")\n",
    "    except Exception as e:\n",
    "        print(f\"ID3 test 4 failed runtime error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116f2b2-c937-4c0e-b9c8-50c6e7acd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221204c8-b585-4426-8039-1689aa1f6ac0",
   "metadata": {},
   "source": [
    "## Plot Learning Curves\n",
    "\n",
    "**Implement Training and Testing with and without Pruning**\n",
    "\n",
    "* Implement the logic to train the decision tree on various training set sizes (ranging between 10 and 300 examples).\n",
    "* For each training size:\n",
    "    * Perform 100 random runs.\n",
    "    * In each run, use the selected training examples to train the tree.\n",
    "    * Test the tree on all examples not used for training.\n",
    "    * Record the accuracy for each run.\n",
    "\n",
    "**Plot Learning Curves**\n",
    "\n",
    "* For each training size, calculate the average accuracy across the 100 runs.\n",
    "* Plot the learning curves:\n",
    "    * X-axis: Number of training examples.\n",
    "    * Y-axis: Average accuracy on the test data.\n",
    "* Create two lines on the plot:\n",
    "    * One line representing accuracy with pruning and the other line representing accuracy without pruning.\n",
    "    * Remember to connect the points for each line to visualize the trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366fe1f-eb01-486a-96d2-da1ef1a5b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    training_sizes,\n",
    "    avg_accuracies_with_pruning,\n",
    "    avg_accuracies_without_pruning,\n",
    "    dataset_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves.\n",
    "\n",
    "    Args:\n",
    "        training_sizes: List of training set sizes\n",
    "        avg_accuracies_with_pruning: List of average accuracies with pruning\n",
    "        avg_accuracies_without_pruning: List of average accuracies\n",
    "                                        without pruning\n",
    "        dataset_name: name of the dataset of plot title and image filename.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_accuracies_with_pruning,\n",
    "        label=\"With Pruning\",\n",
    "        color=\"orange\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_accuracies_without_pruning,\n",
    "        label=\"Without Pruning\",\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Training Examples\")\n",
    "    plt.ylabel(\"Average Accuracy on Test Data\")\n",
    "    plt.title(f\"Learning Curves for {dataset_name} Data With and Without Pruning\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"images/learning_curve_{dataset_name}.png\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved image as images/learning_curve_{dataset_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2ff20-8faf-4a0f-a421-0b8d276c0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = range(10, 305, 5)\n",
    "loop_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c79da-9515-482b-b5bd-9049ac434807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse(\"house_votes_84.data\")\n",
    "avg_test_accuracy_with_pruning = []\n",
    "avg_test_accuracy_without_pruning = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a42da-79ca-4892-afdb-26429c3f3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_size in training_sizes:\n",
    "    with_pruning = []\n",
    "    without_pruning = []\n",
    "\n",
    "    for _ in range(loop_size):\n",
    "        random.shuffle(data)\n",
    "        validation_size = max(1, math.ceil((int(train_size / 0.8) - train_size) // 2))\n",
    "        test_size = validation_size\n",
    "        train = data[:train_size]\n",
    "        valid = data[train_size : train_size + validation_size]\n",
    "        test = data[\n",
    "            train_size + validation_size : train_size + validation_size + test_size\n",
    "        ]\n",
    "\n",
    "        # pruned tree\n",
    "        tree = ID3(train, 0)\n",
    "        prune(tree, valid)\n",
    "        acc = test_tree(tree, test)\n",
    "        with_pruning.append(acc)\n",
    "\n",
    "        # non-pruned tree\n",
    "        tree = ID3(train + valid, 0)\n",
    "        acc = test_tree(tree, test)\n",
    "        without_pruning.append(acc)\n",
    "\n",
    "    avg_accuracy_with_pruning = sum(with_pruning) / len(with_pruning)\n",
    "    avg_accuracy_without_pruning = sum(without_pruning) / len(without_pruning)\n",
    "    avg_test_accuracy_with_pruning.append(avg_accuracy_with_pruning)\n",
    "    avg_test_accuracy_without_pruning.append(avg_accuracy_without_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b41529-23e3-428b-9d90-c52d0b8d4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_with_pruning,\n",
    "    avg_test_accuracy_without_pruning,\n",
    "    dataset_name=\"House Data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494f859-5ca0-4827-b41e-84d701e142ee",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "\n",
    "```txt\n",
    "               ,@@@@@@@,\n",
    "       ,,,.   ,@@@@@@/@@,  .oo8888o.\n",
    "    ,&%%&%&&%,@@@@@/@@@@@@,8888\\88/8o\n",
    "   ,%&\\%&&%&&%,@@@\\@@@/@@@88\\88888/88'\n",
    "   %&&%&%&/%&&%@@\\@@/ /@@@88888\\88888'\n",
    "   %&&%/ %&%%&&@@\\ V /@@' `88\\8 `/88'\n",
    "   `&%\\ ` /%&'    |.|        \\ '|8'\n",
    "       |o|        | |         | |\n",
    "       |.|        | |         | |\n",
    "jgs \\\\/ ._\\//_/__/  ,\\_//__\\\\/.  \\_//__/_\n",
    "```\n",
    "\n",
    "* In this section you will be building and evaluating a Random Forest classifier.\n",
    "* Ensure you have your ID3 implementation ready, as you will be using it to construct the trees in your Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c60c22-33c2-44cf-90c6-ec7e5c0f7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    Random Forest - an ensemble learning technique that builds multiple trees.\n",
    "    Here, we're building trees using bootstrapping (sampling with replacement)\n",
    "\n",
    "    Attributes:\n",
    "        random_forest_nodes (list): A list to store the decision tree nodes\n",
    "                                     in the random forest.\n",
    "        num_trees (int): The number of decision trees in the random forest.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        self.random_forest_nodes = []\n",
    "        self.num_trees = num_trees\n",
    "\n",
    "    def fit(self, examples):\n",
    "        \"\"\"\n",
    "        Fits the random forest to a dataset using bootstrapped samples and\n",
    "        creates decision trees.\n",
    "        \"\"\"\n",
    "        for _ in range(self.num_trees):\n",
    "            # create a bootstrapped sample by randomly selecting an example n\n",
    "            # times; with replacement, i.e., can select one example more than\n",
    "            # once; n = len(examples)\n",
    "            bootstrap_sample = [random.choice(examples) for _ in range(len(examples) + 1)]\n",
    "            available_attributes = [\n",
    "                attribute for attribute in examples[0].keys() if attribute != \"Class\"\n",
    "            ]\n",
    "            subset_attributes = set(\n",
    "                random.sample(\n",
    "                    available_attributes,\n",
    "                    random.randint(2, len(available_attributes)),\n",
    "                )\n",
    "            )\n",
    "            random_forest_node = ID3_helper(bootstrap_sample, subset_attributes)\n",
    "            self.random_forest_nodes.append(random_forest_node)\n",
    "\n",
    "    def test_tree(self, examples, return_predictions=False):\n",
    "        \"\"\"\n",
    "        Tests the accuracy of the random forest on a dataset.\n",
    "        If return_predictions is True, it returns the predictions for all examples.\n",
    "        Otherwise, it returns the accuracy.\n",
    "        \"\"\"\n",
    "        predictions = [self.evaluate(example) for example in examples]\n",
    "\n",
    "        if return_predictions:\n",
    "            # Return the list of predictions for confusion matrix\n",
    "            return predictions\n",
    "\n",
    "        # Calculate accuracy if return_predictions is False\n",
    "        num_correct_predictions = sum(\n",
    "            [pred == example[\"Class\"] for pred, example in zip(predictions, examples)]\n",
    "        )\n",
    "        return num_correct_predictions / len(examples)\n",
    "\n",
    "    def evaluate(self, example):\n",
    "        \"\"\"\n",
    "        Evaluates a single example using the random forest's ensemble of\n",
    "        decision trees. Use majority voting to predict the class.\n",
    "        \"\"\"\n",
    "        predictions = [\n",
    "            evaluate(random_forest_node, example)\n",
    "            for random_forest_node in self.random_forest_nodes\n",
    "        ]\n",
    "        return get_most_common_class(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5458-350d-4fe5-b712-979bf13396a5",
   "metadata": {},
   "source": [
    "**Best Number of Trees:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe0313-b515-4ed7-a957-8b7891651d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse(\"candy.data\")\n",
    "num_trees_accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118984e-0b97-4910-a926-946a665441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_trees in range(2, 15):\n",
    "    accuracies = []\n",
    "    for _ in range(25):\n",
    "        random.shuffle(data)\n",
    "        split_index = int(0.8 * len(data))\n",
    "        train = data[:split_index]\n",
    "        test = data[split_index:]\n",
    "\n",
    "        random_forest = RandomForest(num_trees)\n",
    "        random_forest.fit(train)\n",
    "        acc = random_forest.test_tree(test)\n",
    "        accuracies.append(acc)\n",
    "    num_trees_accuracies[num_trees] = sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6646bf-6eaa-4f56-9815-b82a5c01330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = list(num_trees_accuracies.keys())\n",
    "accuracy = list(num_trees_accuracies.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trees, accuracy, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Random Forest Accuracy vs. Number of Trees\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Average Accuracy on Test Data\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"images/rf_num_trees_accuracies.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc5f9e-95c9-4668-bf66-2a2bfb1f0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_trees = max(num_trees_accuracies, key=lambda key: num_trees_accuracies[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ae8d-2fad-4253-8808-2378e077d3e3",
   "metadata": {},
   "source": [
    "**Comparison with ID3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280b73b-5545-4430-a6cc-e03b2082ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_accuracy_id3_pruning = []\n",
    "avg_test_accuracy_id3_not_pruning = []\n",
    "avg_test_accuracy_rf = []\n",
    "avg_train_accuracy_id3_pruning = []\n",
    "avg_train_accuracy_id3_not_pruning = []\n",
    "avg_train_accuracy_rf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a48da6-e487-4125-a909-b00b1e7518c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = range(5, 68, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85357425-ef6e-4f42-9a6e-7506b9055cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_size in training_sizes:\n",
    "    with_pruning_acc_test = []\n",
    "    without_pruning_acc_test = []\n",
    "    rf_acc_test = []\n",
    "    with_pruning_acc_train = []\n",
    "    without_pruning_acc_train = []\n",
    "    rf_acc_train = []\n",
    "\n",
    "    for _ in range(25):\n",
    "        random.shuffle(data)\n",
    "        validation_size = max(1, math.ceil((int(train_size / 0.8) - train_size) // 2))\n",
    "        test_size = validation_size\n",
    "        train = data[:train_size]\n",
    "        valid = data[train_size : train_size + validation_size]\n",
    "        test = data[\n",
    "            train_size + validation_size : train_size + validation_size + test_size\n",
    "        ]\n",
    "\n",
    "        tree = ID3(train, 0)\n",
    "        acc = test_tree(tree, train)\n",
    "        with_pruning_acc_train.append(acc)\n",
    "        prune(tree, valid)\n",
    "        acc = test_tree(tree, test)\n",
    "        with_pruning_acc_test.append(acc)\n",
    "\n",
    "        tree = ID3(train + valid, 0)\n",
    "        acc = test_tree(tree, train + valid)\n",
    "        without_pruning_acc_train.append(acc)\n",
    "        acc = test_tree(tree, test)\n",
    "        without_pruning_acc_test.append(acc)\n",
    "\n",
    "        random_forest = RandomForest(num_trees)\n",
    "        random_forest.fit(train + valid)\n",
    "        acc = random_forest.test_tree(train + valid)\n",
    "        rf_acc_train.append(acc)\n",
    "        acc = random_forest.test_tree(test)\n",
    "        rf_acc_test.append(acc)\n",
    "\n",
    "    avg_test_accuracy_id3_pruning.append(\n",
    "        sum(with_pruning_acc_test) / len(with_pruning_acc_test)\n",
    "    )\n",
    "    avg_test_accuracy_id3_not_pruning.append(\n",
    "        sum(without_pruning_acc_test) / len(without_pruning_acc_test)\n",
    "    )\n",
    "    avg_test_accuracy_rf.append(sum(rf_acc_test) / len(rf_acc_test))\n",
    "    avg_train_accuracy_id3_pruning.append(\n",
    "        sum(with_pruning_acc_train) / len(with_pruning_acc_train)\n",
    "    )\n",
    "    avg_train_accuracy_id3_not_pruning.append(\n",
    "        sum(without_pruning_acc_train) / len(without_pruning_acc_train)\n",
    "    )\n",
    "    avg_train_accuracy_rf.append(sum(rf_acc_train) / len(rf_acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae732d-e2b1-4c4c-8f31-2270832d0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_forest_id3_accuracies(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_id3_pruning,\n",
    "    avg_test_accuracy_id3_not_pruning,\n",
    "    avg_test_accuracy_rf,\n",
    "    avg_train_accuracy_id3_pruning,\n",
    "    avg_train_accuracy_id3_not_pruning,\n",
    "    avg_train_accuracy_rf,\n",
    "    dataset_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_id3_pruning,\n",
    "        label=\"[Test] ID3 (With Pruning)\",\n",
    "        color=\"orange\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_id3_not_pruning,\n",
    "        label=\"[Test] ID3 (Without Pruning)\",\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_test_accuracy_rf,\n",
    "        label=\"[Test] Random Forest\",\n",
    "        color=\"green\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_id3_pruning,\n",
    "        label=\"[Train] ID3 (With Pruning)\",\n",
    "        color=\"orange\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_id3_not_pruning,\n",
    "        label=\"[Train] ID3 (Without Pruning)\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        training_sizes,\n",
    "        avg_train_accuracy_rf,\n",
    "        label=\"[Train] Random Forest\",\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Training Examples\")\n",
    "    plt.ylabel(\"Average Accuracy\")\n",
    "    plt.title(\n",
    "        f\"Learning Curves for {dataset_name} Data - ID3 (With and Without Pruning) vs Random Forest\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"images/id3_vs_rf_{dataset_name}.png\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved image as images/id3_vs_rf_{dataset_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b4b97-9810-44ab-bff7-3fa6a9c39bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_forest_id3_accuracies(\n",
    "    training_sizes,\n",
    "    avg_test_accuracy_id3_pruning,\n",
    "    avg_test_accuracy_id3_not_pruning,\n",
    "    avg_test_accuracy_rf,\n",
    "    avg_train_accuracy_id3_pruning,\n",
    "    avg_train_accuracy_id3_not_pruning,\n",
    "    avg_train_accuracy_rf,\n",
    "    \"Candy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11944651-c607-41cd-b7c3-7a32060c1cf9",
   "metadata": {},
   "source": [
    "Finally, comparing accuracies and fetching a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51204e46-2de7-4f57-81d3-07de07ac4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_pruning_acc = []\n",
    "without_pruning = []\n",
    "rf_acc = []\n",
    "\n",
    "with_pruning_pred = []\n",
    "without_pruning_pred = []\n",
    "rf_pred = []\n",
    "actual_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102f834-8de1-4413-9b55-cd98840128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    random.shuffle(data)\n",
    "    train = data[: len(data) // 2]\n",
    "    valid = data[len(data) // 2 : 3 * len(data) // 4]\n",
    "    test = data[3 * len(data) // 4 :]\n",
    "\n",
    "    # Store actual labels\n",
    "    actual = [example[\"Class\"] for example in test]\n",
    "    actual_labels.extend(actual)\n",
    "\n",
    "    # ID3 with pruning\n",
    "    tree = ID3(train, 0)\n",
    "    prune(tree, valid)\n",
    "    predictions = test_tree(tree, test, return_predictions=True)\n",
    "    acc = sum(\n",
    "        [pred == example[\"Class\"] for pred, example in zip(predictions, test)]\n",
    "    ) / len(test)\n",
    "    with_pruning_acc.append(acc)\n",
    "    with_pruning_pred.extend(predictions)\n",
    "\n",
    "    # ID3 without pruning\n",
    "    tree = ID3(train + valid, 0)\n",
    "    predictions = test_tree(tree, test, return_predictions=True)\n",
    "    acc = sum(\n",
    "        [pred == example[\"Class\"] for pred, example in zip(predictions, test)]\n",
    "    ) / len(test)\n",
    "    without_pruning.append(acc)\n",
    "    without_pruning_pred.extend(predictions)\n",
    "\n",
    "    # Random Forest\n",
    "    random_forest = RandomForest(num_trees)\n",
    "    random_forest.fit(train + valid)\n",
    "    predictions = random_forest.test_tree(test, return_predictions=True)\n",
    "    acc = sum(\n",
    "        [pred == example[\"Class\"] for pred, example in zip(predictions, test)]\n",
    "    ) / len(test)\n",
    "    rf_acc.append(acc)\n",
    "    rf_pred.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a68e08-3239-4d78-ba68-a02adb49ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print average accuracy for each model\n",
    "print(\"Avg accuracy of ID3 with pruning: \", sum(with_pruning_acc) / len(with_pruning_acc))\n",
    "print(\n",
    "    \"Avg accuracy of ID3 without pruning: \", sum(without_pruning) / len(without_pruning)\n",
    ")\n",
    "print(\"Avg accuracy of Random Forest: \", sum(rf_acc) / len(rf_acc))\n",
    "\n",
    "# Generate and print confusion matrices\n",
    "print(\"Confusion Matrix for ID3 with Pruning:\")\n",
    "conf_matrix_with_pruning = confusion_matrix(actual_labels, with_pruning_pred)\n",
    "print(conf_matrix_with_pruning)\n",
    "\n",
    "print(\"Confusion Matrix for ID3 without Pruning:\")\n",
    "conf_matrix_without_pruning = confusion_matrix(actual_labels, without_pruning_pred)\n",
    "print(conf_matrix_without_pruning)\n",
    "\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "conf_matrix_rf = confusion_matrix(actual_labels, rf_pred)\n",
    "print(conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9badb5-b8ee-4371-8da7-fed86a5c2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
